{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax  regression model\n",
    "\n",
    "The following notebook describes the creation of a softmax  regression model for the classification of german traffic signs, using tensorflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduardo\\Anaconda\\Miniconda3\\envs\\dl\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn.metrics import accuracy_score\n",
    "from PIL import Image\n",
    "import glob\n",
    "import inspect\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of the train and test images\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "ruta_train = os.sep.join([current_dir,'..','images','train'])\n",
    "ruta_test = os.sep.join([current_dir,'..','images','test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test images\n",
    "\n",
    "train_images = []\n",
    "test_images = []\n",
    "\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "for filename in glob.iglob(ruta_train + os.sep + '*.ppm'):\n",
    "    label = int(filename.split(os.sep)[-1].split('_')[0])\n",
    "    y_train.append(label)\n",
    "    train_images.append(Image.open(filename))\n",
    "\n",
    "for filename in glob.iglob(ruta_test + os.sep + '*.ppm'):\n",
    "    label = int(filename.split(os.sep)[-1].split('_')[0])\n",
    "    y_test.append(label)\n",
    "    test_images.append(Image.open(filename))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "# Resizes an image to a defined size, and then reshapes into a 1xn array\n",
    "def process_img(img,size):\n",
    "    out = img.resize(size, Image.ANTIALIAS)\n",
    "    out = np.asarray(out)\n",
    "    out = out.reshape(1, -1)\n",
    "    return out\n",
    "\n",
    "# Applies the process_img function to the train and test sets of images, and return train and test arrays\n",
    "def formar_set(images,im_size):\n",
    "    X = [process_img(img, im_size) for img in images]\n",
    "    X = np.vstack(X)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "im_size = (25,25)\n",
    "learning_rate = 0.0002\n",
    "batch_size = 500\n",
    "training_iteration = 10000 # max number of iterations\n",
    "termination_margin = 0.001/100  # If the cost function varies less than this between iterations, the training process stops.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and normalize training and test feature sets\n",
    "\n",
    "X_train = formar_set(train_images,im_size)\n",
    "X_test = formar_set(test_images,im_size)\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255\n",
    "\n",
    "# Convert class vectors (y_train and y_test) to binary class matrices\n",
    "\n",
    "Y_train = np.array(pd.get_dummies(pd.Series(y_train)))\n",
    "Y_test = np.array(pd.get_dummies(pd.Series(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create tf model\n",
    "\n",
    "size_x = X_train.shape[1]\n",
    "size_y = Y_train.shape[1]\n",
    "\n",
    "# TF graph input\n",
    "x = tf.placeholder(\"float\", [None, size_x], name='x') \n",
    "y = tf.placeholder(\"float\", [None, size_y], name='y') \n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(tf.zeros([size_x, size_y]), name='W')\n",
    "b = tf.Variable(tf.zeros([size_y]), name='b')\n",
    "\n",
    "# Construct a linear model\n",
    "model = tf.nn.softmax(tf.matmul(x, W) + b, name='model') # Softmax\n",
    "\n",
    "# Define cross_entropy as the cost function\n",
    "cost_function = -tf.reduce_sum(y*tf.log(model))\n",
    "                \n",
    "# Define Gradient Descent as the model optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0200 cost= 425.841522217\n",
      "Iteration: 0400 cost= 341.389770508\n",
      "Iteration: 0600 cost= 297.994110107\n",
      "Iteration: 0800 cost= 271.810913086\n",
      "Iteration: 1000 cost= 253.999069214\n",
      "Iteration: 1200 cost= 240.741668701\n",
      "Iteration: 1400 cost= 229.161178589\n",
      "Iteration: 1600 cost= 222.790481567\n",
      "Iteration: 1800 cost= 215.310287476\n",
      "Iteration: 2000 cost= 209.352294922\n",
      "Iteration: 2200 cost= 204.311813354\n",
      "Iteration: 2400 cost= 199.871398926\n",
      "Iteration: 2600 cost= 196.757476807\n",
      "Iteration: 2800 cost= 193.443664551\n",
      "Iteration: 3000 cost= 190.292480469\n",
      "Iteration: 3200 cost= 187.830810547\n",
      "Iteration: 3400 cost= 185.606170654\n",
      "Iteration: 3600 cost= 183.634246826\n",
      "Iteration: 3800 cost= 182.056106567\n",
      "Iteration: 4000 cost= 180.721725464\n",
      "Iteration: 4200 cost= 178.679595947\n",
      "Iteration: 4400 cost= 177.486831665\n",
      "Iteration: 4600 cost= 176.305892944\n",
      "Iteration: 4800 cost= 174.545379639\n",
      "Iteration: 5000 cost= 173.875915527\n",
      "Iteration: 5200 cost= 172.557647705\n",
      "Iteration: 5400 cost= 171.688003540\n",
      "Iteration: 5600 cost= 171.739501953\n",
      "Iteration: 5800 cost= 170.154403687\n",
      "Iteration: 6000 cost= 169.759643555\n",
      "Iteration: 6200 cost= 169.026489258\n",
      "Iteration: 6400 cost= 168.309555054\n",
      "Iteration: 6600 cost= 168.632705688\n",
      "Iteration: 6800 cost= 167.833267212\n",
      "Iteration: 7000 cost= 167.122390747\n",
      "Iteration: 7200 cost= 166.924011230\n",
      "Iteration: 7350 cost= 166.918029785\n",
      "Tuning completed!\n",
      "Training accuracy: 0.9937106966972351\n",
      "Test accuracy: 0.876447856426239\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize variables and calculate initial cost\n",
    "    sess.run(init)\n",
    "    initial_cost = sess.run(cost_function,{x:X_test,y:Y_test})\n",
    "    cond = True\n",
    "    overfit = False\n",
    "    cont = 0\n",
    "  \n",
    "    # Training cycle\n",
    "    while cond:\n",
    "        cont += 1\n",
    "        rand_ind = random.sample(range(len(X_train)),batch_size)\n",
    "        batch_xs, batch_ys = X_train[rand_ind,:],Y_train[rand_ind,:]\n",
    "        \n",
    "        sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        cost_epoch = sess.run(cost_function,{x:X_test,y:Y_test})\n",
    "        \n",
    "        # Progress is printed every 200 iterations\n",
    "        if cont % 200 == 0:\n",
    "            print(\"Iteration:\", '%04d' % (cont), \"cost=\", \"{:.9f}\".format(cost_epoch))\n",
    "            \n",
    "        # Progress is checked every 50 iterations\n",
    "        if cont % 50 == 0:\n",
    "            overfit = (cost_epoch > initial_cost) and (abs(cost_epoch - initial_cost)/initial_cost < termination_margin)\n",
    "        \n",
    "        # Termination condition\n",
    "        if (cont >= training_iteration) or overfit:\n",
    "            print(\"Iteration:\", '%04d' % (cont), \"cost=\", \"{:.9f}\".format(cost_epoch))\n",
    "            cond = False\n",
    "        else:\n",
    "            initial_cost = cost_epoch\n",
    "        \n",
    "    print(\"Tuning completed!\")\n",
    "    \n",
    "    # Measuring performance\n",
    "    sess.run(cost_function,{x:X_test,y:Y_test})\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(model,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,'float'))\n",
    "\n",
    "    print('Training accuracy: {0}'.format(sess.run(accuracy, feed_dict={x: X_train, y: Y_train})))\n",
    "    print('Test accuracy: {0}'.format(sess.run(accuracy, feed_dict={x: X_test, y: Y_test})))\n",
    "    \n",
    "    #Create a saver object which will save all the variables\n",
    "    model_location = os.sep.join([current_dir,'..','models','model2','model2'])\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, model_location,global_step=1000)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\eduardo\\Desktop\\Reto Kiwi\\German traffic signs detector\\reports\\..\\models\\model2\\model2-1000\n",
      "[15 16 16 17 17 17 17 17 17 18 26 18 18 18]\n",
      "[15, 16, 16, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18]\n"
     ]
    }
   ],
   "source": [
    "x_s = X_test[166:180]\n",
    "# x_s = x_s.reshape(1,-1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    new_saver = tf.train.import_meta_graph('C:/Users/eduardo/Desktop/Reto Kiwi/German traffic signs detector/models/model2/model2-1000.meta')\n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint('C:/Users/eduardo/Desktop/Reto Kiwi/German traffic signs detector/models/model2/'))\n",
    "    pred = tf.argmax(model,1)\n",
    "    print(sess.run(pred,feed_dict={x:x_s}))\n",
    "    \n",
    "#     graph = tf.get_default_graph()\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "#     x = graph.get_tensor_by_name(\"x:0\")\n",
    "#     W = graph.get_tensor_by_name(\"W:0\")\n",
    "#     b = graph.get_tensor_by_name(\"b:0\")\n",
    "    \n",
    "#     model = graph.get_tensor_by_name(\"model:0\")\n",
    "# #     y = graph.get_tensor_by_name(\"y\")\n",
    "#     pred = tf.argmax(model,1)\n",
    "       \n",
    "#     print(sess.run(pred,feed_dict={x: x_s}))\n",
    "print(y_test[166:180])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
